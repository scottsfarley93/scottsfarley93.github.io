<!DOCTYPE html>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>Scott Farley</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
	<link href="https://api.mapbox.com/mapbox-assembly/v0.19.0/assembly.min.css" rel="stylesheet">
	<link href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" rel="stylhesheet">
	<script src='https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js'></script>
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css">
	<link rel='stylesheet' href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js">
	<link rel="stylesheet" href="/assets/css/main.css" />
	<link rel='stylesheet' href="/assets/css/highlight.css" />
	<!--[if lte IE 9]><link rel="stylesheet" href="/assets/css/ie9.css" /><![endif]-->
	<!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->
	<script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
	<link rel='stylesheet' href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.10.0/css/lightbox.min.css"/>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.10.0/js/lightbox-plus-jquery.min.js"></script>
	<link rel='stylesheet' href="/assets/css/photography.css" />
</head>


<body>

    <!-- Wrapper -->
<div id="wrapper">

<!-- Header -->
<!-- <header id="header">
	<a href="/" class="logo"><strong>Scott Farley</strong> <span></span></a>
	<nav>
		<a href="#menu">Menu</a>
	</nav>
</header> -->

<!-- Menu -->
<!-- <nav id="menu">
	<ul class="links">
        
		    
		
		    
		        <li><a href="/"></a></li>
	    	
		
		    
		
		    
		
		
		    
		        <li><a href="/blog.html">Blog</a></li>
		    
		
		    
		
		    
		
		    
		        <li><a href="/photography.html">Photgraphy</a></li>
		    
		
	</ul>
</nav> -->
 
    
    
<!-- Main -->
<div id="main" class="alt">

<!-- One -->
<section id="one">
	<div class="inner">
		<header class="major">
			<h1>Scenery-based routing: A deep learning approach</h1>
		</header>
		
		<p><style>
  .blogImg{
    width: 50%;
  }
</style>

<p>tl;dr; as a hobby project, I‚Äôve been developing a method for routing vehicles over a road network optimizing for the scenic-ness of the path by using street-level imagery. Here are some take-aways I thought could be more broadly applicable.</p>

<p>What if we could give directions not based on time or distance, but on characteristics of the road the user will drive on?</p>

<p>If all else were equal, I‚Äôd rather drive on this‚Ä¶</p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513980153115_thumb-2048.jpg" alt="" /></p>

<p>than on this‚Ä¶</p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513980145644_thumb-2048+1.jpg" alt="" /></p>

<p>Typically, we route users by minimizing the time it will take them to get from Point A to Point B. While this will be the best objective in most cases, there are cases when a user may maximize other objectives, such as the beauty of the scenery encountered along their route. Consider a user planning a road trip or who has extra time in a foreign city. They know they‚Äôd like to travel from A to B, but they‚Äôd rather experience the place than solely minimizing the time it takes to traverse the route.</p>

<p>\ I‚Äôve tinkered with a way to assign quantitative metrics of scenic value based on street-level imagery to ways in a network graph so that the network can be used in routing applications. I think this could be of broader interested, so I‚Äôm sharing some of my explorations here.</p>

<h2 id="approach">Approach</h2>

<p><strong>Objective</strong>: build a routable road network where the edge weights are a quantitative metric of the ‚Äúscenic-ness‚Äù of that edge.</p>

<p>To accomplish this we‚Äôll use a machine learning approach to classify road segments as ‚Äúscenic‚Äù or ‚Äúnot scenic‚Äù. First, we‚Äôll gather a bunch of Mapillary images from ‚Äúscenic‚Äù road segments and a bunch of images from ‚Äúun-scenic‚Äù road segments. Then we‚Äôll build a model to learn the difference between the two. Using this model, we‚Äôll test images from all roads in our network to a 0 (not scenic) to 1 (very scenic) score for each image. We can test multiple images for each segment and then assign the average value of these images as the ‚Äúscenic score‚Äù for that segment. Then we ingest the road graph into a routing engine (postgres/postgis/pgrouting stack).</p>

<h2 id="data">Data</h2>

<ol>
  <li><strong>Positive Labels:</strong> We know that some road segments are objectively more scenic than others. State and local governments classify roads that are especially beautify and natural as scenic highways. In California,</li>
</ol>

<blockquote>
  <p>A highway may be designated scenic depending upon how much of the natural landscape can be seen by travelers, the scenic quality of the landscape, and the extent to which development intrudes upon the traveler‚Äôs enjoyment of the view.</p>
</blockquote>

<p>We can get the location of official scenic highway designations from the Caltrans, the state highway department. Any images taken from along these segments should, thus, have a high scenic quality. These images will serve as our positive training examples.</p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513981117131_Screen+Shot+2017-12-22+at+2.18.22+PM.png" alt="" /></p>

<ol>
  <li>
    <p><strong>Negative Labels:</strong> Negative image labels are harder to come by without manual tagging. There are plenty of non-scenic roads that are just regular roads, without any official designation. However, I didn‚Äôt feel like doing any manual image tagging, so I used <strong>interstates</strong> as road segments that were prototypically un-scenic.
<img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513981240871_Screen+Shot+2017-12-22+at+2.18.59+PM.png" alt="" /></p>
  </li>
  <li>
    <p><strong>Testing/Routing Network:</strong> To maximize the number of roads that would have Mapillary coverage, while keeping compute times reasonable, I chose primary and secondary roads as the routing dataset. This means that there won‚Äôt be a lot of local variation, but it let‚Äôs us experiment with the whole state pretty easily.
<img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513981462004_Screen+Shot+2017-12-22+at+2.24.05+PM.png" alt="" /></p>
  </li>
</ol>

<h1>#</h1>
<ol>
  <li><strong>Images:</strong> I iterated over all the features in each dataset. For each feature, I randomly sampled ten points along the line. For each randomly sampled location, I downloaded (up to) ten randomly selected streetview images from within 100m of that location, using the Mapillary API.</li>
</ol>

<h2 id="visual-analysis">Visual Analysis</h2>

<p>To see if an algorithm had even a chance of learning the difference between these two classes, I did a TSNE on the images. I plotted the results and checked to see how clearly discriminated the clusters were. If all the images were really jumbled together, any algorithm would have little change to delineate between the classes.</p>

<p>It turns out that groups of positive and negative images are pretty tightly clustered across the embedded space.</p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513985376886_embedding_2.png" alt="" /></p>

<p>They‚Äôre not perfectly clustered, but it looks like we‚Äôll have a good shot at choosing one class or the other.</p>

<p>These figures are also just fun to look at.</p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513986009415_embedding_4.png" alt="" /></p>

<h2 id="training">Training</h2>

<p>I used Keras to train a pretty simple deep neural net. It looked like this (but could definitely used some optimization):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #  
=================================================================
conv2d_32 (Conv2D)           (None, 100, 100, 50)      1400      
_________________________________________________________________
batch_normalization_29 (Batc (None, 100, 100, 50)      400      
_________________________________________________________________
max_pooling2d_28 (MaxPooling (None, 50, 50, 50)        0        
_________________________________________________________________
conv2d_33 (Conv2D)           (None, 50, 50, 50)        22550    
_________________________________________________________________
batch_normalization_30 (Batc (None, 50, 50, 50)        200      
_________________________________________________________________
max_pooling2d_29 (MaxPooling (None, 25, 25, 50)        0        
_________________________________________________________________
conv2d_34 (Conv2D)           (None, 25, 25, 50)        22550    
_________________________________________________________________
batch_normalization_31 (Batc (None, 25, 25, 50)        100      
_________________________________________________________________
max_pooling2d_30 (MaxPooling (None, 12, 12, 50)        0        
_________________________________________________________________
conv2d_35 (Conv2D)           (None, 12, 12, 50)        22550    
_________________________________________________________________
batch_normalization_32 (Batc (None, 12, 12, 50)        48        
_________________________________________________________________
max_pooling2d_31 (MaxPooling (None, 6, 6, 50)          0        
_________________________________________________________________
conv2d_36 (Conv2D)           (None, 6, 6, 50)          22550    
_________________________________________________________________
batch_normalization_33 (Batc (None, 6, 6, 50)          24        
_________________________________________________________________
max_pooling2d_32 (MaxPooling (None, 3, 3, 50)          0        
_________________________________________________________________
flatten_8 (Flatten)          (None, 450)               0        
_________________________________________________________________
dense_22 (Dense)             (None, 512)               230912    
_________________________________________________________________
dense_23 (Dense)             (None, 256)               131328    
_________________________________________________________________
dense_24 (Dense)             (None, 1)                 257      
=================================================================
Total params: 454,869
Trainable params: 454,483
Non-trainable params: 386
_________________________________________________________________
</code></pre></div></div>

<p>It contains five convolutional layers and three dense layers.</p>

<p>After some training, I was able to get to about <strong>87% accuracy</strong> on a validation set. There were more scenic road segments than interstate segments in my dataset, so I selected an even number of images in each class to prevent the model output having a class imbalance bias.</p>

<p>More training, more images, and a better network architecture could probably lead to better accuracy. But 87% accuracy seems pretty good for now.</p>

<h2 id="model-predictions">Model Predictions</h2>

<p>Below are some randomly chosen model predictions and their associated scenic-score (1 is most scenic).</p>

<ol>
  <li>
    <p>What did it think was scenic?
<img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513982402423_image.png" alt="" /></p>
  </li>
  <li>
    <p>What did it think was not scenic?
<img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513982426770_image.png" alt="" /></p>
  </li>
  <li>
    <p>What did it <strong>incorrectly</strong> predict as scenic (but actually wasn‚Äôt):
<img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513982463345_image.png" alt="" /></p>
  </li>
  <li>
    <p>What did it <strong>incorrectly</strong> predict as not scenic (but actually was):
<img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513982533854_image.png" alt="" /></p>
  </li>
</ol>

<p>It looks the network is doing a pretty good job at delineating roads that appear scenic from those that appear not scenic.</p>

<h2 id="routing">Routing</h2>

<p>After training the model, I downloaded multiple images for every segment in the testing network. Some segments didn‚Äôt have Mapillary images on them (üòû ), so they were assigned a default value of 0.5 (neither scenic nor unscenic). For those segments that did have images, each images was given a predicted score of [0, 1]. For segments with more than one image (most segments), the image scores were averaged together to create a single numeric scenic-ness score for each segment.</p>

<p>I then ingested the geojson with the road geometries and the scenic-ness scores into a postgres/postgis table.</p>

<p>Follow some tutorials I found online, I made it routable by creating a network topology. Once it was properly set up, I could query the resulting table with sql to find the most scenic route between two points:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SELECT * FROM pgr_dijkstra(
  'SELECT id,
       source,
       target,
       1 - meanScore as cost
      FROM edges_noded',
  1, 5,
  directed := false);
</code></pre></div></div>

<p>I had to correct for the fact that the scenic-ness scoring routine I developed gave more scenic routes a higher score (closer to one), but the shortest path algorithms attempt to find the lowest cost routes through a graph (e.g., I selected <code class="highlighter-rouge">1-meanScore</code> as cost instead of just <code class="highlighter-rouge">meanScore</code> as cost).</p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513986747492_Screen+Shot+2017-12-22+at+3.52.13+PM.png" alt="Shortest Route" /></p>

<p>Shortest Route</p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513986747552_Screen+Shot+2017-12-22+at+3.52.02+PM.png" alt="Least Scenic Route" /></p>

<p>Least scenic route</p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513986747641_Screen+Shot+2017-12-22+at+3.51.52+PM.png" alt="Most Scenic Route" /></p>

<p>Most scenic route</p>

<p><em>Optimal routes between San Diego and Eureka, according to different optimization criteria.</em></p>

<p><img src="https://d2mxuefqeaa7sj.cloudfront.net/s_F816EA582A1DC83209F892C5D7B2B73978791B5CF81606E539981E26315FE35B_1513986997322_Screen+Shot+2017-12-22+at+3.56.25+PM.png" alt="" /></p>

<p><em>The most scenic route between San Jose and the Inner Sunset, according to the model.</em></p>

<h2 id="whats-next">What‚Äôs Next?</h2>

<p>There‚Äôs a lot more we could do with this type of model.</p>

<ul>
  <li>Improve the model:
    <ul>
      <li>More training epoches</li>
      <li>More training data</li>
      <li>More layers</li>
    </ul>
  </li>
  <li>Expand the model:
    <ul>
      <li>Include more states than just California. Different states‚Äô scenic roads are likely to run through vastly different types of environments. To capture this variety, we‚Äôd want to train the model with data from these different environments.</li>
    </ul>
  </li>
  <li>Improve the network
    <ul>
      <li>Normalize the graph.</li>
      <li>There are some topology issues in the graph that, if corrected, would improve routeability</li>
      <li>Include more than just primary roads. Mapillary covers more than just the primary and secondary roads. To really get good routes, we‚Äôd need to include many more roads than the skeleton network shown here. This would vastly increase computation, but would probably be worth it because we could do much better small-scale routing (like across a city).</li>
    </ul>
  </li>
  <li>
    <p>Improve the cost function ‚Äî develop something like a distance-weighted scenic score. This would favor scenic roads of non-scenic ones, but wouldn‚Äôt take me all the way across the state.</p>
  </li>
  <li>Extend the ideas to different objectives.
    <ul>
      <li><strong><em>bike-ability:</em></strong> train on images of <a href="https://en.wikipedia.org/wiki/Bicycle_boulevard">bicycle boulevards</a> ‚Äî streets that have been optimized for bicycle traffic. Then predict the level of bicycle friendly-ness for the road network. This could be a nice addition to biking directions by ensuring that, when a street is not technically classed as a bike-lane, it is still nice to bike on. It might also allow better biking directions in cities that do not have officially designated bike-ways or in cities for which this data is not available.</li>
    </ul>
  </li>
</ul>

</p>
	</div>
</section>

</div>

    
<!-- Footer -->
<div class='align-center'>
	<footer id="footer" class='pt24 align-center'>
		<div class="inner">
			<ul class="icons">
				
				<li><a href="https://twitter.com/scottsfarley93" class="icon alt fa-twitter" target="_blank"><span class="label">Twitter</span></a></li>
				
				
				
				
				<li><a href="https://www.instagram.com/scottsfarley/" class="icon alt fa-instagram" target="_blank"><span class="label">Instagram</span></a></li>
				
				
				
				
				
				<li><a href="http://github.com/scottsfarley93" class="icon alt fa-github" target="_blank"><span class="label">GitHub</span></a></li>
				
				
				
				<li><a href="https://www.linkedin.com/in/scott-farley-25902581" class="icon alt fa-linkedin" target="_blank"><span class="label">LinkedIn</span></a></li>
				
			</ul>
			<ul class="copyright mb0">
				<li>&copy; Scott Farley </li>
			</ul>
		</div>
	</footer>

</div>

<!-- Scripts -->
	<script src="/assets/js/jquery.min.js"></script>
	<script src="/assets/js/jquery.scrolly.min.js"></script>
	<script src="/assets/js/jquery.scrollex.min.js"></script>
	<script src="/assets/js/skel.min.js"></script>
	<script src="/assets/js/util.js"></script>
	<!--[if lte IE 8]><script src="/assets/js/ie/respond.min.js"></script><![endif]-->
	<script src="/assets/js/main.js"></script>


</body>

</html>